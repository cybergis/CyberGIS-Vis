{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program creates Neighborhood Delination across different time period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOSNAP2NAM start at 2020-10-05 03:39:56\n",
      "To see visualization of your analysis, click the URL below:\n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/view/geosnap-viz/Qualitative_Geographic_Data_Visualization/QUAL_Cook_2018_from_ACS_zipcode_from_file/index.html\n",
      "Advanced options are available in \n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/edit/geosnap-viz/Qualitative_Geographic_Data_Visualization/QUAL_Cook_2018_from_ACS_zipcode_from_file/data/GEO_CONFIG_Cook_2018_from_ACS_zipcode_from_file.js\n",
      "GEOSNAP2NAM ended at 2020-10-05 03:39:58    Elapsed 00:00:02\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import json, math, copy, sys\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "import shapely.geometry\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import urllib.parse\n",
    "import webbrowser\n",
    "import os\n",
    "import pprint\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from notebook import notebookapp\n",
    "from IPython.core.display import display, HTML\n",
    "import geopandas as gpd\n",
    "\n",
    "def Clustering_viz(param):\n",
    "    write_INDEX_html(param)\n",
    "    write_CONFIG_js(param)\n",
    "    write_VARIABLES_js(param)\n",
    "    write_GEO_JSON_js(param)\n",
    "    \n",
    "    #Create directory for VIZ in CyberGISX    \n",
    "    servers = list(notebookapp.list_running_servers())\n",
    "    servers1 = 'https://cybergisx.cigi.illinois.edu'+servers[0][\"base_url\"]+ 'view'\n",
    "    servers2 = 'https://cybergisx.cigi.illinois.edu'+servers[0][\"base_url\"]+ 'edit'      \n",
    "    cwd = os.getcwd()\n",
    "    prefix_cwd = \"/home/jovyan/work\"\n",
    "    cwd = cwd.replace(prefix_cwd, \"\")\n",
    "    local_dir1 = servers1 + cwd\n",
    "    local_dir2 = servers2 + cwd    \n",
    "    #print(local_dir)\n",
    "    fname =urllib.parse.quote('index.html')\n",
    "    template_dir = os.path.join(local_dir1, 'QUAL_' + param['filename_suffix'])\n",
    "    #url = 'file:' + os.path.join(template_dir, fname)\n",
    "    url = os.path.join(template_dir, fname)    \n",
    "    webbrowser.open(url)\n",
    "    print('To see visualization of your analysis, click the URL below:')\n",
    "    print(url)    \n",
    "    print('Advanced options are available in ')  \n",
    "    print(local_dir2 + '/'+ 'QUAL_' + param['filename_suffix']+'/data/GEO_CONFIG_' + param['filename_suffix']+'.js')    \n",
    "\n",
    "    \n",
    "def write_INDEX_html(param):\n",
    "    #Create a new folder where GEO_CONFIG.js GEO_JSON.js VARIABLES.js will be saved\n",
    "    oDir = 'QUAL_' + param['filename_suffix']\n",
    "    path = Path(oDir + '/data')\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    contents = []\n",
    "    #open Neighborhood_Analysis_Mapper.html (the excutable file for the visualization)\n",
    "    ifile = open(\"template/Qualitative_Analysis_Mapper.html\", \"r\", encoding=\"utf-8\")\n",
    "    contents = ifile.read()\n",
    "    \n",
    "    #Replace variables based on the user's selection in each of four files below.\n",
    "    contents = contents.replace(\"Neighborhood Analysis Mapper\", param['title'])\n",
    "    contents = contents.replace(\"data/CONFIG.js\", \"data/CONFIG_\"+param['filename_suffix']+\".js\")\n",
    "    contents = contents.replace(\"data/GEO_JSON.js\", \"data/GEO_JSON_\"+param['filename_suffix']+\".js\")\n",
    "    contents = contents.replace(\"data/VARIABLES.js\", \"data/VARIABLES_\"+param['filename_suffix']+\".js\")\n",
    "    \n",
    "    #write new outfiles: GEO_CONFIG.js GEO_JSON.js VARIABLES.js\n",
    "    ofile = open(oDir+\"/index.html\", \"w\", encoding=\"utf-8\")\n",
    "    ofile.write(contents)\n",
    "    ofile.close()\n",
    "    #print (contents)    \n",
    "    \n",
    "def write_CONFIG_js(param):\n",
    "    # read ACM_GEO_CONFIG.js\n",
    "    ifile = open(\"template/QUAL_CONFIG.js\", \"r\", encoding=\"utf-8\")\n",
    "    contents = ifile.read()\n",
    "    \n",
    "    SubjectName = \"\";\n",
    "    Maps_of_neighborhood = True;               \n",
    "    Temporal_change_in_neighborhoods = True;\n",
    "    Parallel_Categories_Diagram_in_neighborhoods = True;\n",
    "    Chord_Diagram_in_neighborhoods = True;\n",
    "    \n",
    "    if ('subject' in param): SubjectName =  param['subject']\n",
    "    if ('Maps_of_neighborhood' in param): Maps_of_neighborhood =  param['Maps_of_neighborhood']\n",
    "    if ('Temporal_change_in_neighborhoods' in param): Temporal_change_in_neighborhoods =  param['Temporal_change_in_neighborhoods']\n",
    "    if ('Parallel_Categories_Diagram_in_neighborhoods' in param): Parallel_Categories_Diagram_in_neighborhoods =  param['Parallel_Categories_Diagram_in_neighborhoods']\n",
    "    if ('Chord_Diagram_in_neighborhoods' in param): Chord_Diagram_in_neighborhoods =  param['Chord_Diagram_in_neighborhoods']\n",
    "    \n",
    "    InitialLayers = []\n",
    "    if (len(param['Layers']) <= 1): InitialLayers = []\n",
    "    for i, year in enumerate(param['Layers']):\n",
    "        InitialLayers.append(str(year))\n",
    "\n",
    "    NumOfMaps = len(InitialLayers)\n",
    "    # Automatically set Map_width, Map_height. \n",
    "    Map_width = \"300px\"\n",
    "    Map_height = \"300px\"\n",
    "    if (NumOfMaps <= 6):\n",
    "        Map_width = \"300px\"\n",
    "        Map_height = \"300px\"\t\n",
    "    if (NumOfMaps <= 5):\n",
    "        Map_width = \"350px\"\n",
    "        Map_height = \"350px\"\n",
    "    if (NumOfMaps <= 4):\n",
    "        Map_width = \"400px\"\n",
    "        Map_height = \"400px\"\n",
    "    if (NumOfMaps <= 3):\n",
    "        Map_width = \"400px\"\n",
    "        Map_height = \"400px\"\n",
    "    if (NumOfMaps <= 2):\n",
    "        Map_width = \"450px\"\n",
    "        Map_height = \"450px\"\n",
    "    if (NumOfMaps ==\t1):\n",
    "        Map_width = \"800px\"\n",
    "        Map_height = \"800px\"\n",
    "    \n",
    "    # replace newly computed \"NumOfMaps\", \"InitialLayers\", \"Map_width\", \"Map_height\" in CONFIG.js. See the example replacement below\n",
    "    InitialLayers = \"var InitialLayers = \" + json.dumps(InitialLayers) + \";\"\n",
    "    SubjectName = 'var SubjectName = \"' + SubjectName + '\";'\n",
    "    Maps_of_neighborhood = \"var Maps_of_neighborhood = \" + json.dumps(Maps_of_neighborhood)+ \";\"\n",
    "    Temporal_change_in_neighborhoods = \"var Temporal_change_in_neighborhoods = \" + json.dumps(Temporal_change_in_neighborhoods)+ \";\"\n",
    "    Parallel_Categories_Diagram_in_neighborhoods = \"var Parallel_Categories_Diagram_in_neighborhoods = \" + json.dumps(Parallel_Categories_Diagram_in_neighborhoods)+ \";\"\n",
    "    Chord_Diagram_in_neighborhoods = \"var Chord_Diagram_in_neighborhoods = \" + json.dumps(Chord_Diagram_in_neighborhoods)+ \";\"\n",
    "    Map_width = 'var Map_width  = \"' + Map_width + '\";'\n",
    "    Map_height = 'var Map_height = \"' + Map_height + '\";'\n",
    "    \n",
    "    contents = contents.replace(\"var InitialLayers = [];\", InitialLayers)\n",
    "    contents = contents.replace('var SubjectName = \"\";', SubjectName)\n",
    "    contents = contents.replace(\"var Maps_of_neighborhood = true;\", Maps_of_neighborhood)\n",
    "    contents = contents.replace(\"var Temporal_change_in_neighborhoods = true;\", Temporal_change_in_neighborhoods)\n",
    "    contents = contents.replace(\"var Parallel_Categories_Diagram_in_neighborhoods = true;\", Parallel_Categories_Diagram_in_neighborhoods)\n",
    "    contents = contents.replace(\"var Chord_Diagram_in_neighborhoods = true;\", Chord_Diagram_in_neighborhoods)\n",
    "    contents = contents.replace('var Map_width  = \"400px\";', Map_width)\n",
    "    contents = contents.replace('var Map_height = \"400px\";', Map_height)\n",
    "    \n",
    "    #Write output including the replacement above\n",
    "    filename_GEO_CONFIG = \"QUAL_\" + param['filename_suffix'] + \"/data/CONFIG_\"+param['filename_suffix']+\".js\"\n",
    "    ofile = open(filename_GEO_CONFIG, 'w', encoding=\"utf-8\")\n",
    "    ofile.write(contents)\n",
    "    ofile.close()    \n",
    "    #print (contents)        \n",
    "\n",
    "def write_GEO_JSON_js(param):    \n",
    "    # read shape file to df_shape\n",
    "    df_shapes = gpd.read_file(param['shapefile'])\n",
    "    df_shapes = df_shapes.rename(columns={'GEOID10': 'geoid'})\n",
    "    df_shapes = df_shapes.astype(str)\n",
    "    geoid = df_shapes.columns[0]\n",
    "    df_shapes = df_shapes[pd.notnull(df_shapes['geometry'])]\n",
    "    \n",
    "    # open GEO_JSON.js write heading for geojson format\n",
    "    filename_GEO_JSON = \"QUAL_\" + param['filename_suffix'] + \"/data/GEO_JSON_\"+param['filename_suffix']+\".js\"\n",
    "    ofile = open(filename_GEO_JSON, 'w')\n",
    "    ofile.write('var GEO_JSON =\\n')\n",
    "    ofile.write('{\"type\":\"FeatureCollection\", \"features\": [\\n')\n",
    "    \n",
    "    #Convert geometry in GEOJSONP to geojson format\n",
    "    wCount = 0\n",
    "    for shape in df_shapes.itertuples():\n",
    "        feature = {\"type\":\"Feature\"}\n",
    "        if (type(shape.geometry) is float):\t\t\t\t\t\t\t\t# check is NaN?\n",
    "            #print(tract.geometry)\n",
    "            continue\n",
    "        #print(tract.geometry)\n",
    "        aShape = shapely.wkt.loads(shape.geometry)\n",
    "        feature[\"geometry\"] = shapely.geometry.mapping(aShape)\n",
    "        #feature[\"properties\"] = {geoid: tract.__getattribute__(geoid), \"tractID\": tract.__getattribute__(geoid)}\n",
    "        feature[\"properties\"] = {geoid: shape.__getattribute__(geoid)}\n",
    "        wCount += 1\n",
    "        ofile.write(json.dumps(feature)+',\\n')\n",
    "    #print(\"GEO_JSON.js write count:\", wCount)\n",
    "    # complete the geojosn format by adding parenthesis at the end.\t\n",
    "    ofile.write(']}\\n')\n",
    "    ofile.close()    \n",
    "    \n",
    "    \n",
    "def write_VARIABLES_js(param):\n",
    "    #if ('Sequence' not in param or not param['Sequence']): df_pivot.drop(columns=['Sequence'], inplace=True)\n",
    "    df_pivot = pd.read_csv(param[\"inputCSV\"])    \n",
    "    df_pivot.set_index(geoid, inplace=True)\n",
    "    # write df_wide to GEO_VARIABLES.js\n",
    "    filename_GEO_VARIABLES = \"QUAL_\" + param['filename_suffix'] + \"/data/VARIABLES_\"+param['filename_suffix']+\".js\"\n",
    "    ofile = open(filename_GEO_VARIABLES, 'w')\n",
    "    ofile.write('var GEO_VARIABLES =\\n')\n",
    "    ofile.write('[\\n')\n",
    "    \n",
    "    heading = [geoid]\n",
    "    heading.extend(list(map(str, df_pivot.columns.tolist())))\n",
    "    ofile.write('  '+json.dumps(heading)+',\\n')\n",
    "    wCount = 0\n",
    "    for i, row in df_pivot.reset_index().iterrows():\n",
    "        aLine = row.tolist()\n",
    "        for j, col in enumerate(aLine[2:], 2):\n",
    "            try:\n",
    "                aLine[j] = int(col)                                  # convert float to int\n",
    "            except ValueError:\n",
    "                aLine[j] = -9999                                     # if Nan, set -9999\n",
    "        wCount += 1 \n",
    "        ofile.write('  '+json.dumps(aLine)+',\\n')\n",
    "    #print(\"GEO_VARIABLES.js write count:\", wCount)\n",
    "    ofile.write(']\\n')\n",
    "    ofile.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    started_datetime = datetime.now()\n",
    "    dateYYMMDD = started_datetime.strftime('%Y%m%d')\n",
    "    timeHHMMSS = started_datetime.strftime('%H%M%S')\n",
    "    print('GEOSNAP2NAM start at %s %s' % (started_datetime.strftime('%Y-%m-%d'), started_datetime.strftime('%H:%M:%S')))\n",
    "    \n",
    "    param = {\n",
    "        'title': \"Neighborhood, Cook County (zipcode level)\",\n",
    "        'subject': \"NEIGHBORHOOD\",\n",
    "        'filename_suffix': \"Cook_2018_from_ACS_zipcode_from_file\", \n",
    "        'Layers': [1980,2000,2010],\n",
    "        'inputCSV': \"attributes/Input_attributes.csv\",   \n",
    "        'shapefile': \"shp/Cook_County_Tract.shp\", \n",
    "        'Maps_of_neighborhood': True,                #choropleth map: Maps representing clustering result\t\t\n",
    "        'Temporal_change_in_neighborhoods': False,    #stacked chart: Temporal Change in Neighborhoods over years\t\t\n",
    "        'Parallel_Categories_Diagram_in_neighborhoods': False,\n",
    "        'Chord_Diagram_in_neighborhoods': True\n",
    "    }\n",
    "\n",
    "    Clustering_viz(param) \n",
    "    ended_datetime = datetime.now()\n",
    "    elapsed = ended_datetime - started_datetime\n",
    "    total_seconds = int(elapsed.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds,60*60)\n",
    "    minutes, seconds = divmod(remainder,60)\t\n",
    "    print('GEOSNAP2NAM ended at %s %s    Elapsed %02d:%02d:%02d' % (ended_datetime.strftime('%Y-%m-%d'), ended_datetime.strftime('%H:%M:%S'), hours, minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To see visualization of your analysis, click the URL below:\n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/view/geosnap-viz/Qualitative_Geographic_Data_Visualization/QUAL_Cook_2018_from_ACS_zipcode_from_file/index.html\n",
      "Advanced options are available in \n",
      "https://cybergisx.cigi.illinois.edu/user/suhanmappingideas/edit/geosnap-viz/Qualitative_Geographic_Data_Visualization/QUAL_Cook_2018_from_ACS_zipcode_from_file/data/GEO_CONFIG_Cook_2018_from_ACS_zipcode_from_file.js\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'title': \"Neighborhood, Cook County (zipcode level)\",\n",
    "    'subject': \"NEIGHBORHOOD\",\n",
    "    'filename_suffix': \"Cook_2018_from_ACS_zipcode_from_file\", \n",
    "    'Layers': [1980,1990,2000,2010],\n",
    "    'inputCSV': \"attributes/Input_attributes.csv\",   \n",
    "    'shapefile': \"shp/Cook_County_Tract.shp\", \n",
    "    'Maps_of_neighborhood': True,                #choropleth map: Maps representing clustering result\t\t\n",
    "    'Temporal_change_in_neighborhoods': False,    #stacked chart: Temporal Change in Neighborhoods over years\t\t\n",
    "    'Parallel_Categories_Diagram_in_neighborhoods': False,\n",
    "    'Chord_Diagram_in_neighborhoods': True\n",
    "}\n",
    "Clustering_viz(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
